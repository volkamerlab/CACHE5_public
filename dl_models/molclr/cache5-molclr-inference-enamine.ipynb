{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-28T19:33:07.470586Z",
     "iopub.status.busy": "2024-05-28T19:33:07.469940Z",
     "iopub.status.idle": "2024-05-28T19:34:28.441760Z",
     "shell.execute_reply": "2024-05-28T19:34:28.440770Z",
     "shell.execute_reply.started": "2024-05-28T19:33:07.470545Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rdkit\n",
      "  Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rdkit) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from rdkit) (9.5.0)\n",
      "Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m34.9/34.9 MB\u001B[0m \u001B[31m2.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: rdkit\n",
      "Successfully installed rdkit-2023.9.6\n",
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m64.2/64.2 kB\u001B[0m \u001B[31m526.9 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (4.66.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.11.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2024.2.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.9.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch_geometric) (5.9.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch_geometric) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torch_geometric) (2024.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
      "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m1.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.5.3\n",
      "Collecting lightning\n",
      "  Downloading lightning-2.2.5-py3-none-any.whl.metadata (53 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m53.4/53.4 kB\u001B[0m \u001B[31m783.9 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.2.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.4)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\n",
      "Requirement already satisfied: torch<4.0,>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.2)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.3.2)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.9.0)\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.2.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (69.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.13.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.1.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=1.13.0->lightning) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.6)\n",
      "Downloading lightning-2.2.5-py3-none-any.whl (2.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m9.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: lightning\n",
      "Successfully installed lightning-2.2.5\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (4.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.7/6.7 MB\u001B[0m \u001B[31m24.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: wandb\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.16.6\n",
      "    Uninstalling wandb-0.16.6:\n",
      "      Successfully uninstalled wandb-0.16.6\n",
      "Successfully installed wandb-0.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install rdkit\n",
    "!pip install torch_geometric\n",
    "!pip install lightning -U\n",
    "!pip install wandb -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-28T19:34:28.444105Z",
     "iopub.status.busy": "2024-05-28T19:34:28.443796Z",
     "iopub.status.idle": "2024-05-28T19:34:39.905584Z",
     "shell.execute_reply": "2024-05-28T19:34:39.904644Z",
     "shell.execute_reply.started": "2024-05-28T19:34:28.444075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import lightning as L\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from scipy.stats import pearsonr\n",
    "import sklearn.metrics as skmetrics\n",
    "from collections import defaultdict\n",
    "from torch_geometric.loader import DataLoader\n",
    "import wandb\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../input'):\n",
    "    if dirname.find(\".git\") >= 0 or dirname.find(\"wandb\") >= 0:\n",
    "        continue\n",
    "    filenames = [filename for filename in filenames if not filename.startswith(\"__\")]\n",
    "    for filename in filenames[:5]:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    wandb_api = UserSecretsClient().get_secret(\"wandb_key\") \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    wandb_api = None\n",
    "if wandb_api is not None:\n",
    "    wandb.login(key=wandb_api)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:34:39.907063Z",
     "iopub.status.busy": "2024-05-28T19:34:39.906643Z",
     "iopub.status.idle": "2024-05-28T19:34:39.911144Z",
     "shell.execute_reply": "2024-05-28T19:34:39.910320Z",
     "shell.execute_reply.started": "2024-05-28T19:34:39.907038Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DRAFT_MODE = False #True\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "target_names = [\"pIC50\", \"pKi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:34:39.913880Z",
     "iopub.status.busy": "2024-05-28T19:34:39.913315Z",
     "iopub.status.idle": "2024-05-28T19:34:39.928952Z",
     "shell.execute_reply": "2024-05-28T19:34:39.928018Z",
     "shell.execute_reply.started": "2024-05-28T19:34:39.913848Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../input/cleaned-enamine/cleaned_enamine.csv')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Path(\"../input/cleaned-enamine\").iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:34:39.930262Z",
     "iopub.status.busy": "2024-05-28T19:34:39.929973Z",
     "iopub.status.idle": "2024-05-28T19:34:39.935258Z",
     "shell.execute_reply": "2024-05-28T19:34:39.934437Z",
     "shell.execute_reply.started": "2024-05-28T19:34:39.930240Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# full_df = pd.read_csv(\"../input/cleaned-enamine/cleaned_enamine.csv\")\n",
    "# full_df.shape\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:20.532350Z",
     "iopub.status.busy": "2024-05-28T19:36:20.531666Z",
     "iopub.status.idle": "2024-05-28T19:36:29.835532Z",
     "shell.execute_reply": "2024-05-28T19:36:29.834576Z",
     "shell.execute_reply.started": "2024-05-28T19:36:20.532318Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000000, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TID</th>\n",
       "      <th>SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PV-009095522958</td>\n",
       "      <td>FCC(CF)NC(CF)CF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z5067467525</td>\n",
       "      <td>FC(F)(F)C12CC(NC3CSCSC3)(CO1)C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PV-009234181902</td>\n",
       "      <td>CCN(CC1C2CC3C(C2)C13)C(C)(C)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Z7289498217</td>\n",
       "      <td>Br/C=C\\CN1C2CC3CC1CC(C2)O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PV-008660388768</td>\n",
       "      <td>CC(N[C@H]1[C@@H]2C[C@H]1N[C@@H]2C)C1C(C)(C)C1(C)C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TID                                             SMILES\n",
       "0  PV-009095522958                                    FCC(CF)NC(CF)CF\n",
       "1      Z5067467525                    FC(F)(F)C12CC(NC3CSCSC3)(CO1)C2\n",
       "2  PV-009234181902                      CCN(CC1C2CC3C(C2)C13)C(C)(C)C\n",
       "3      Z7289498217                         Br/C=C\\CN1C2CC3CC1CC(C2)O3\n",
       "4  PV-008660388768  CC(N[C@H]1[C@@H]2C[C@H]1N[C@@H]2C)C1C(C)(C)C1(C)C"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = 5000000\n",
    "# with pd.read_csv(\"../input/cleaned-enamine/cleaned_enamine.csv\", chunksize=chunk_size) as reader:\n",
    "#     for chunk_index, full_df in enumerate(reader):\n",
    "#         full_df.to_csv(f\"enamine_chunk_{chunk_index}_{chunk_size}.csv\", index=None)\n",
    "\n",
    "CHUNK = 0\n",
    "full_df = pd.read_csv(f\"../input/enamine-split-to-chunks/enamine_chunk_{CHUNK}_{chunk_size}.csv\")\n",
    "print(full_df.shape)\n",
    "if DRAFT_MODE:\n",
    "    full_df = full_df.head(2000)\n",
    "print(full_df.shape)\n",
    "\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:29.837466Z",
     "iopub.status.busy": "2024-05-28T19:36:29.837093Z",
     "iopub.status.idle": "2024-05-28T19:36:29.848196Z",
     "shell.execute_reply": "2024-05-28T19:36:29.847345Z",
     "shell.execute_reply.started": "2024-05-28T19:36:29.837441Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 2407\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "    \n",
    "RANDOM_STATE=2407\n",
    "set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:29.850048Z",
     "iopub.status.busy": "2024-05-28T19:36:29.849734Z",
     "iopub.status.idle": "2024-05-28T19:36:30.040206Z",
     "shell.execute_reply": "2024-05-28T19:36:30.039329Z",
     "shell.execute_reply.started": "2024-05-28T19:36:29.850021Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data, InMemoryDataset, Dataset\n",
    "from rdkit import Chem\n",
    "\n",
    "from rdkit.Chem.rdchem import BondType as BT\n",
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "ATOM_LIST = list(range(1,119))\n",
    "CHIRALITY_LIST = [\n",
    "    Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n",
    "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
    "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
    "    Chem.rdchem.ChiralType.CHI_OTHER\n",
    "]\n",
    "BOND_LIST = [BT.SINGLE, BT.DOUBLE, BT.TRIPLE, BT.AROMATIC]\n",
    "BONDDIR_LIST = [\n",
    "    Chem.rdchem.BondDir.NONE,\n",
    "    Chem.rdchem.BondDir.ENDUPRIGHT,\n",
    "    Chem.rdchem.BondDir.ENDDOWNRIGHT\n",
    "]\n",
    "\n",
    "\n",
    "def smiles2pyg_data(smiles, regression_target=None, classification_target=None, **kwargs):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    mol = Chem.AddHs(mol)\n",
    "\n",
    "    num_atoms = mol.GetNumAtoms()\n",
    "    num_bonds = mol.GetNumBonds()\n",
    "\n",
    "    type_idx = []\n",
    "    chirality_idx = []\n",
    "    atomic_number = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        type_idx.append(ATOM_LIST.index(atom.GetAtomicNum()))\n",
    "        chirality_idx.append(CHIRALITY_LIST.index(atom.GetChiralTag()))\n",
    "        atomic_number.append(atom.GetAtomicNum())\n",
    "\n",
    "    x1 = torch.tensor(type_idx, dtype=torch.long).view(-1,1)\n",
    "    x2 = torch.tensor(chirality_idx, dtype=torch.long).view(-1,1)\n",
    "    x = torch.cat([x1, x2], dim=-1)\n",
    "\n",
    "    row, col, edge_feat = [], [], []\n",
    "    for bond in mol.GetBonds():\n",
    "        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        row += [start, end]\n",
    "        col += [end, start]\n",
    "        edge_feat.append([\n",
    "            BOND_LIST.index(bond.GetBondType()),\n",
    "            BONDDIR_LIST.index(bond.GetBondDir())\n",
    "        ])\n",
    "        edge_feat.append([\n",
    "            BOND_LIST.index(bond.GetBondType()),\n",
    "            BONDDIR_LIST.index(bond.GetBondDir())\n",
    "        ])\n",
    "\n",
    "    edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "    edge_attr = torch.tensor(np.array(edge_feat), dtype=torch.long)\n",
    "    # if target is None:\n",
    "    #     return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, **kwargs)\n",
    "    #if task == 'classification':\n",
    "    #    y = torch.tensor(target, dtype=torch.long).view(1,-1)\n",
    "    #elif task == 'regression':\n",
    "    #    y = torch.tensor(target, dtype=torch.float).view(1,-1)\n",
    "    if regression_target is not None:\n",
    "        regression_target = torch.tensor(regression_target, dtype=torch.float).view(1,-1)\n",
    "        kwargs['regression_target'] = regression_target\n",
    "    if classification_target is not None:\n",
    "        classification_target = torch.tensor(classification_target, dtype=torch.long)  #.view(1,-1)\n",
    "        kwargs['classification_target'] = classification_target\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, **kwargs)\n",
    "    return data\n",
    "\n",
    "\n",
    "class CacheDataset(Dataset):\n",
    "    def __init__(self, df, smiles_column=\"smiles\", inference_mode=False, additional_columns=[], root=\"../temp/temp_cache\", transform=None, pre_transform=None, pre_filter=None):\n",
    "        assert isinstance(df, pd.DataFrame)\n",
    "\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.df = df\n",
    "        self.inference_mode = inference_mode\n",
    "        self.additional_columns = [\n",
    "            column for column in additional_columns if column in df.columns\n",
    "        ]\n",
    "\n",
    "        self.data_index = np.asarray(df.index)\n",
    "        self.smiles_column = smiles_column #\"smiles\"\n",
    "        self.regression_column = \"acvalue_uM\"\n",
    "        self.classification_column = \"class\"\n",
    "        self.regression_name_column = \"acname\"\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "        # return [self.filename]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return []\n",
    "    def len(self):\n",
    "        return len(self.data_index)\n",
    "\n",
    "    def get(self, idx):\n",
    "        index = self.data_index[idx]\n",
    "        smiles = self.df.loc[index, self.smiles_column]\n",
    "        kwargs = {}\n",
    "        if len(self.additional_columns) > 0:\n",
    "            for column in self.additional_columns:\n",
    "                kwargs[column] = self.df.loc[index, column]\n",
    "        if not self.inference_mode:\n",
    "            regression_name = self.df.loc[index, self.regression_name_column]\n",
    "            regression_value = self.df.loc[index, self.regression_column]\n",
    "            classification_value = self.df.loc[index, self.classification_column]\n",
    "            kwargs['regression_target'] = regression_value\n",
    "            kwargs['classification_target'] = classification_value\n",
    "            kwargs['regression_name'] = regression_name\n",
    "\n",
    "        return smiles2pyg_data(smiles, **kwargs)\n",
    "\n",
    "    def process(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:30.063762Z",
     "iopub.status.busy": "2024-05-28T19:36:30.063505Z",
     "iopub.status.idle": "2024-05-28T19:36:30.078188Z",
     "shell.execute_reply": "2024-05-28T19:36:30.077342Z",
     "shell.execute_reply.started": "2024-05-28T19:36:30.063741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FC(nn.Module):\n",
    "    def __init__(self, d_graph_layer, fc_hidden_dim, dropout, n_tasks):\n",
    "        super(FC, self).__init__()\n",
    "\n",
    "        self.predict = nn.ModuleList()\n",
    "        for index, dim in enumerate(fc_hidden_dim):\n",
    "            self.predict.append(nn.Linear(d_graph_layer, dim))\n",
    "            self.predict.append(nn.Dropout(dropout))\n",
    "            self.predict.append(nn.LeakyReLU())\n",
    "            self.predict.append(nn.BatchNorm1d(dim))\n",
    "            d_graph_layer = dim\n",
    "        self.predict.append(nn.Linear(d_graph_layer, n_tasks))\n",
    "\n",
    "    def forward(self, h):\n",
    "        for layer in self.predict:\n",
    "            h = layer(h)\n",
    "        # return torch.sigmoid(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class RankingLoss(nn.Module):\n",
    "    def __init__(self, embedding_out_dim, dropout=0.3, ntasks=2):\n",
    "        super(RankingLoss, self).__init__()\n",
    "        #self.config = config\n",
    "        self.loss_fn = nn.CrossEntropyLoss() # TODO: check this - was reduce=False #reduce=False)\n",
    "        #if config.model.readout.startswith('multi_head') and config.model.attn_merge == 'concat':\n",
    "        #    self.relation_mlp = FC(embedding_out_dim * (config.model.num_head + 1) * 2, \n",
    "        #    [embedding_out_dim * 2, embedding_out_dim], dropout, 2)\n",
    "        #else:\n",
    "        self.embedding_out_dim = embedding_out_dim\n",
    "        self.relation_mlp = FC(\n",
    "            embedding_out_dim * 2, \n",
    "            [embedding_out_dim, embedding_out_dim // 2], \n",
    "            dropout, \n",
    "            ntasks\n",
    "        )\n",
    "        self.m = nn.Softmax(dim=1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_rank_relation(self, y_A, y_B):\n",
    "        # y_A: [batch, 1]\n",
    "        # target_relation: 0: <=, 1: >\n",
    "        target_relation = torch.zeros(y_A.size(), dtype=torch.long, device=y_A.device)\n",
    "        target_relation[(y_A - y_B) > 0.0] = 1\n",
    "\n",
    "        return target_relation.squeeze()\n",
    "\n",
    "    def forward(self, output_embedding, target):\n",
    "        batch_repeat_num = len(output_embedding)\n",
    "        # if batch_repeat_num // 2 < 1 and batch_repeat_num % 2 != 0:\n",
    "        #     return None, None, None\n",
    "        shift = max(batch_repeat_num // 2, 1)\n",
    "        #batch_size = batch_repeat_num // 2\n",
    "        #x_A, y_A, x_B, y_B = output_embedding[:batch_size], target[:batch_size],\\\n",
    "        #                     output_embedding[batch_size:], target[batch_size:]\n",
    "        x_A, y_A = output_embedding, target\n",
    "        x_B = torch.roll(output_embedding, shift, 0)\n",
    "        y_B = torch.roll(target, shift, 0)\n",
    "\n",
    "        relation = self.get_rank_relation(y_A, y_B)\n",
    "        # print(x_A.shape, x_B.shape, y_A.shape, y_B.shape)\n",
    "        relation_pred = self.relation_mlp(torch.cat([x_A, x_B], dim=1))\n",
    "\n",
    "        ranking_loss = self.loss_fn(relation_pred, relation)\n",
    "\n",
    "        _, y_pred = self.m(relation_pred).max(dim=1)\n",
    "\n",
    "        return ranking_loss, relation.squeeze(), y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GINet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:30.080643Z",
     "iopub.status.busy": "2024-05-28T19:36:30.080334Z",
     "iopub.status.idle": "2024-05-28T19:36:30.109432Z",
     "shell.execute_reply": "2024-05-28T19:36:30.108493Z",
     "shell.execute_reply.started": "2024-05-28T19:36:30.080614Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool\n",
    "\n",
    "num_atom_type = 119 # including the extra mask tokens\n",
    "num_chirality_tag = 3\n",
    "\n",
    "num_bond_type = 5 # including aromatic and self-loop edge\n",
    "num_bond_direction = 3 \n",
    "\n",
    "\n",
    "class GINEConv(MessagePassing):\n",
    "    def __init__(self, emb_dim):\n",
    "        super(GINEConv, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 2*emb_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(2*emb_dim, emb_dim)\n",
    "        )\n",
    "        self.edge_embedding1 = nn.Embedding(num_bond_type, emb_dim)\n",
    "        self.edge_embedding2 = nn.Embedding(num_bond_direction, emb_dim)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.edge_embedding1.weight.data)\n",
    "        nn.init.xavier_uniform_(self.edge_embedding2.weight.data)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # add self loops in the edge space\n",
    "        edge_index = add_self_loops(edge_index, num_nodes=x.size(0))[0]\n",
    "\n",
    "        # add features corresponding to self-loop edges.\n",
    "        self_loop_attr = torch.zeros(x.size(0), 2)\n",
    "        self_loop_attr[:,0] = 4 # bond type for self-loop edge\n",
    "        self_loop_attr = self_loop_attr.to(edge_attr) #.to(edge_attr.dtype)\n",
    "        edge_attr = torch.cat((edge_attr, self_loop_attr), dim=0)\n",
    "\n",
    "        edge_embeddings = self.edge_embedding1(edge_attr[:,0]) + \\\n",
    "            self.edge_embedding2(edge_attr[:,1])\n",
    "\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_embeddings)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return self.mlp(aggr_out)\n",
    "\n",
    "\n",
    "class GINet(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        num_layer (int): the number of GNN layers\n",
    "        emb_dim (int): dimensionality of embeddings\n",
    "        drop_ratio (float): dropout rate\n",
    "        gnn_type: gin, gcn, graphsage, gat\n",
    "    Output:\n",
    "        node representations\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        task='classification', num_layer=5, emb_dim=300, feat_dim=512, \n",
    "        drop_ratio=0, pool='mean', pred_n_layer=2, pred_act='softplus'\n",
    "    ):\n",
    "        super(GINet, self).__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.emb_dim = emb_dim\n",
    "        self.feat_dim = feat_dim\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.task = task\n",
    "\n",
    "        self.x_embedding1 = nn.Embedding(num_atom_type, emb_dim)\n",
    "        self.x_embedding2 = nn.Embedding(num_chirality_tag, emb_dim)\n",
    "        nn.init.xavier_uniform_(self.x_embedding1.weight.data)\n",
    "        nn.init.xavier_uniform_(self.x_embedding2.weight.data)\n",
    "\n",
    "        # List of MLPs\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for layer in range(num_layer):\n",
    "            self.gnns.append(GINEConv(emb_dim))\n",
    "\n",
    "        # List of batchnorms\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        for layer in range(num_layer):\n",
    "            self.batch_norms.append(nn.BatchNorm1d(emb_dim))\n",
    "\n",
    "        if pool == 'mean':\n",
    "            self.pool = global_mean_pool\n",
    "        elif pool == 'max':\n",
    "            self.pool = global_max_pool\n",
    "        elif pool == 'add':\n",
    "            self.pool = global_add_pool\n",
    "        self.feat_lin = nn.Linear(self.emb_dim, self.feat_dim)\n",
    "\n",
    "        if self.task == 'classification':\n",
    "            out_dim = 2\n",
    "        elif self.task == 'regression':\n",
    "            out_dim = 1\n",
    "        if self.task != \"head\":\n",
    "            self.pred_n_layer = max(1, pred_n_layer)\n",
    "\n",
    "            if pred_act == 'relu':\n",
    "                pred_head = [\n",
    "                    nn.Linear(self.feat_dim, self.feat_dim//2), \n",
    "                    nn.ReLU(inplace=True)\n",
    "                ]\n",
    "                for _ in range(self.pred_n_layer - 1):\n",
    "                    pred_head.extend([\n",
    "                        nn.Linear(self.feat_dim//2, self.feat_dim//2), \n",
    "                        nn.ReLU(inplace=True),\n",
    "                    ])\n",
    "                pred_head.append(nn.Linear(self.feat_dim//2, out_dim))\n",
    "            elif pred_act == 'softplus':\n",
    "                pred_head = [\n",
    "                    nn.Linear(self.feat_dim, self.feat_dim//2), \n",
    "                    nn.Softplus()\n",
    "                ]\n",
    "                for _ in range(self.pred_n_layer - 1):\n",
    "                    pred_head.extend([\n",
    "                        nn.Linear(self.feat_dim//2, self.feat_dim//2), \n",
    "                        nn.Softplus()\n",
    "                    ])\n",
    "            else:\n",
    "                raise ValueError('Undefined activation function')\n",
    "\n",
    "            pred_head.append(nn.Linear(self.feat_dim//2, out_dim))\n",
    "            self.pred_head = nn.Sequential(*pred_head)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        \n",
    "        h = self.x_embedding1(x[:,0]) + self.x_embedding2(x[:,1])\n",
    "\n",
    "        for layer in range(self.num_layer):\n",
    "            h = self.gnns[layer](h, edge_index, edge_attr)\n",
    "            h = self.batch_norms[layer](h)\n",
    "            if layer == self.num_layer - 1:\n",
    "                h = F.dropout(h, self.drop_ratio, training=self.training)\n",
    "            else:\n",
    "                h = F.dropout(F.relu(h), self.drop_ratio, training=self.training)\n",
    "\n",
    "        h = self.pool(h, data.batch)\n",
    "        h = self.feat_lin(h)\n",
    "        if self.task == \"head\":\n",
    "            return h\n",
    "        return h, self.pred_head(h)\n",
    "\n",
    "    def load_my_state_dict(self, state_dict):\n",
    "        own_state = self.state_dict()\n",
    "        for name, param in state_dict.items():\n",
    "            if name not in own_state:\n",
    "                continue\n",
    "            if isinstance(param, nn.parameter.Parameter):\n",
    "                # backwards compatibility for serialized parameters\n",
    "                param = param.data\n",
    "            own_state[name].copy_(param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common model-related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:30.110910Z",
     "iopub.status.busy": "2024-05-28T19:36:30.110560Z",
     "iopub.status.idle": "2024-05-28T19:36:30.124840Z",
     "shell.execute_reply": "2024-05-28T19:36:30.124055Z",
     "shell.execute_reply.started": "2024-05-28T19:36:30.110856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _load_pre_trained_weights(model, ckpt_path=\"molclr_ckpt\", device='cpu'):\n",
    "    try:\n",
    "        fine_tune_from = 'pretrained_gin'\n",
    "        checkpoints_folder = os.path.join(ckpt_path, fine_tune_from, 'checkpoints')\n",
    "        state_dict = torch.load(os.path.join(checkpoints_folder, 'model.pth'), map_location=device)\n",
    "        # model.load_state_dict(state_dict)\n",
    "        model.load_my_state_dict(state_dict)\n",
    "        print(\"Loaded pre-trained model with success.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Pre-trained weights not found. Training from scratch.\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:33.150280Z",
     "iopub.status.busy": "2024-05-28T19:36:33.149269Z",
     "iopub.status.idle": "2024-05-28T19:36:33.154740Z",
     "shell.execute_reply": "2024-05-28T19:36:33.153799Z",
     "shell.execute_reply.started": "2024-05-28T19:36:33.150248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_params = dict(\n",
    "    num_layer=5,  # number of graph conv layers\n",
    "    emb_dim=300,  # embedding dimension in graph conv layers\n",
    "    feat_dim=512,  # output feature dimention\n",
    "    drop_ratio= 0.3,  # dropout ratio\n",
    "    pool= 'mean'  # readout pooling (i.e., mean/max/add)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:35.639627Z",
     "iopub.status.busy": "2024-05-28T19:36:35.639301Z",
     "iopub.status.idle": "2024-05-28T19:36:35.681431Z",
     "shell.execute_reply": "2024-05-28T19:36:35.680480Z",
     "shell.execute_reply.started": "2024-05-28T19:36:35.639602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MolCLRWrapper(L.LightningModule):\n",
    "    def __init__(self, target_names=[\"pIC50\", \"pKi\"], ckpt_path=None, device='cpu', dropout=0.3):\n",
    "        super().__init__()\n",
    "        # self.device = device\n",
    "        self.target_names = target_names\n",
    "        self.feature_dim = model_params['feat_dim']\n",
    "        self.dropout = model_params['drop_ratio']\n",
    "        self.head = GINet('head', **model_params)\n",
    "\n",
    "        if not ckpt_path is None:\n",
    "            self.head = _load_pre_trained_weights(self.head, ckpt_path=ckpt_path)\n",
    "\n",
    "        self.ranking_losses_func = nn.ModuleDict({\n",
    "            name: RankingLoss(model_params['feat_dim'])\n",
    "            for name in target_names\n",
    "        })\n",
    "\n",
    "        self.regression_heads = nn.ModuleDict({\n",
    "            name: FC(\n",
    "                self.feature_dim, [self.feature_dim // 2, self.feature_dim // 4], \n",
    "                self.dropout, 1\n",
    "            )\n",
    "            for name in target_names\n",
    "        })\n",
    "        self.classification_head = FC(\n",
    "            self.feature_dim, [self.feature_dim // 2, self.feature_dim // 4], \n",
    "            self.dropout, 2\n",
    "        )\n",
    "        # \n",
    "        self.validation_loss_outputs = defaultdict(list)\n",
    "\n",
    "        self.validation_regression_outputs = defaultdict(list)\n",
    "        self.validation_regression_gt = defaultdict(list)\n",
    "        self.validation_classification_outputs = defaultdict(list)\n",
    "        self.validation_classification_gt = defaultdict(list)\n",
    "        \n",
    "        self.test_regression_outputs = defaultdict(list)\n",
    "        self.test_regression_gt = defaultdict(list)\n",
    "        self.test_classification_outputs = []\n",
    "        self.test_classification_gt = []\n",
    "        \n",
    "        self.ranking_lambda = 1.\n",
    "        self.classification_lambda = 1.0\n",
    "        self.regression_lambda = 0.5\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        raise \"training shouldn't be run during inference\"\n",
    "\n",
    "    def forward(self, data_batch):\n",
    "        batch_embeddings, regression_predictions, classification_logits, class_probabilities = self._get_embeddings_and_predictions(data_batch)\n",
    "        return regression_predictions, class_probabilities\n",
    "    \n",
    "    def _get_embeddings_and_predictions(self, data_batch):\n",
    "        regression_predictions = dict()\n",
    "        batch_embeddings = self.head(data_batch)\n",
    "        regression_predictions = {\n",
    "            k: self.regression_heads[k](batch_embeddings)\n",
    "            for k in self.regression_heads\n",
    "        }\n",
    "\n",
    "        classification_logits = self.classification_head(batch_embeddings)\n",
    "        class_probabilities = F.softmax(classification_logits, dim=1)\n",
    "        return batch_embeddings, regression_predictions, classification_logits, class_probabilities\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        batch_embeddings, regression_predictions, classification_logits, class_probabilities = self._get_embeddings_and_predictions(batch)\n",
    "        classification_loss = F.cross_entropy(classification_logits, batch.classification_target)\n",
    "        \n",
    "        target = target_names[dataloader_idx]\n",
    "        ranking_loss, relation, y_pred = self.ranking_losses_func[target](batch_embeddings, batch.regression_target)\n",
    "        \n",
    "        regression_loss = F.mse_loss(regression_predictions[target], batch.regression_target)\n",
    "        val_loss = self.ranking_lambda * ranking_loss + self.regression_lambda * regression_loss + self.classification_lambda * classification_loss\n",
    "        scores = {\n",
    "            'val_loss': val_loss,\n",
    "            'classification_loss': classification_loss,\n",
    "            'regression_loss': regression_loss,\n",
    "        }\n",
    "\n",
    "        self.validation_loss_outputs[dataloader_idx].append(val_loss)\n",
    "        # save regression info\n",
    "        self.validation_regression_outputs[dataloader_idx].append(regression_predictions[target].detach().cpu())\n",
    "        self.validation_regression_gt[dataloader_idx].append(batch.regression_target.detach().cpu())\n",
    "        # save classification info\n",
    "        self.validation_classification_outputs[dataloader_idx].append(class_probabilities.detach().cpu())\n",
    "        self.validation_classification_gt[dataloader_idx].append(batch.classification_target.detach().cpu())\n",
    "        # log scores and return\n",
    "        self.log_dict(scores)\n",
    "        return val_loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        val_losses = []\n",
    "        for dataloader_idx in self.validation_loss_outputs:\n",
    "            val_losses.extend(self.validation_loss_outputs[dataloader_idx])\n",
    "            self.validation_loss_outputs[dataloader_idx].clear()  # free memory\n",
    "        val_losses = torch.stack(val_losses)\n",
    "        scores = {\n",
    "            \"val_loss\": val_losses.sum()\n",
    "        }\n",
    "        # aggregate regression predictions and gt values and compute validation metrics\n",
    "        for dataloader_idx in self.validation_regression_outputs:\n",
    "            outputs = torch.concatenate(self.validation_regression_outputs[dataloader_idx], axis=0).squeeze()\n",
    "            gts = torch.concatenate(self.validation_regression_gt[dataloader_idx], axis=0).squeeze()\n",
    "            scores[f\"reg_MAE_{dataloader_idx}\"] = skmetrics.mean_absolute_error(gts, outputs)\n",
    "            scores[f\"reg_MSE_{dataloader_idx}\"] = skmetrics.mean_squared_error(gts, outputs)\n",
    "            scores[f\"reg_R2_{dataloader_idx}\"] = skmetrics.r2_score(gts, outputs)\n",
    "            \n",
    "            self.validation_regression_outputs[dataloader_idx].clear()\n",
    "            self.validation_regression_gt[dataloader_idx].clear()\n",
    "        # aggregate class predictions and gt values and compute validation metrics\n",
    "        for dataloader_idx in self.validation_classification_outputs:\n",
    "            outputs = torch.concatenate(self.validation_classification_outputs[dataloader_idx], axis=0)[:, 1]\n",
    "            gts = torch.concatenate(self.validation_classification_gt[dataloader_idx], axis=0)\n",
    "            try:\n",
    "                scores[f'classif_roc_auc_{dataloader_idx}'] = skmetrics.roc_auc_score(gts, outputs)\n",
    "                scores[f'classif_accuracy_{dataloader_idx}'] = skmetrics.accuracy_score(gts, outputs > 0.5)\n",
    "                scores[f'classif_f1_{dataloader_idx}'] = skmetrics.f1_score(gts, outputs > 0.5)\n",
    "            except:\n",
    "                continue\n",
    "            self.validation_classification_outputs[dataloader_idx].clear()\n",
    "            self.validation_classification_gt[dataloader_idx].clear()\n",
    "        self.log_dict(scores)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        regression_predictions, class_probabilities = self(batch)\n",
    "        regression_predictions = {\n",
    "            k: v.detach().cpu().numpy() \n",
    "            for k, v in regression_predictions.items()\n",
    "        }\n",
    "        class_probabilities = class_probabilities.detach().cpu().numpy()\n",
    "        regression_gt = batch.regression_target.detach().cpu().numpy()\n",
    "        regression_name = batch.regression_name\n",
    "        target_name = target_names[dataloader_idx]\n",
    "        for name in self.target_names:\n",
    "            preds = regression_predictions[name]\n",
    "            self.test_regression_outputs[name].append(preds)\n",
    "            self.test_regression_gt[name].append(regression_gt)\n",
    "        \n",
    "        classification_gt = batch.classification_target.detach().cpu().numpy()\n",
    "        self.test_classification_outputs.append(class_probabilities)\n",
    "        self.test_classification_gt.append(classification_gt)\n",
    "        \n",
    "    def on_test_epoch_end(self):\n",
    "        data = []\n",
    "        scores = {}\n",
    "        for target_name in target_names:    \n",
    "            pred_values = np.concatenate(self.test_regression_outputs[target_name]).flatten()\n",
    "            gt_values = np.concatenate(self.test_regression_gt[target_name]).flatten()\n",
    "            p = pearsonr(pred_values, gt_values)\n",
    "            scores[f'pearson_{target_name}_pvalue'] = p.pvalue\n",
    "            scores[f'pearson_{target_name}_stat'] = p.statistic\n",
    "\n",
    "            data = [[x, y] for (x, y) in zip(pred_values, gt_values)]\n",
    "            table = wandb.Table(data=data, columns = [\"predictions\", \"true_values\"])\n",
    "            wandb.log({\n",
    "                f\"scatter_{target_name}\": wandb.plot.scatter(\n",
    "                    table, \"predictions\", \"true_values\", title=\"Predicted vs. GT values\")\n",
    "            })\n",
    "            scores[f\"test_reg_MAE_{target_name}\"] = skmetrics.mean_absolute_error(gt_values, pred_values)\n",
    "            scores[f\"test_reg_MSE_{target_name}\"] = skmetrics.mean_squared_error(gt_values, pred_values)\n",
    "            scores[f\"test_reg_R2_{target_name}\"] = skmetrics.r2_score(gt_values, pred_values)\n",
    "            self.test_regression_outputs[target_name].clear()\n",
    "            self.test_regression_gt[target_name].clear()\n",
    "\n",
    "        pred_values = np.concatenate(self.test_classification_outputs)\n",
    "        gt_values = np.concatenate(self.test_classification_gt)\n",
    "        labels_hat = np.argmax(pred_values, axis=1)\n",
    "        \n",
    "        scores[f'test_accuracy'] = skmetrics.accuracy_score(gt_values, labels_hat)\n",
    "        scores[f'test_f1'] = skmetrics.f1_score(gt_values, labels_hat)\n",
    "        test_auc = skmetrics.roc_auc_score(gt_values, pred_values[:, 1])\n",
    "        scores[f'test_auc'] = test_auc\n",
    "\n",
    "        self.test_classification_outputs.clear()\n",
    "        self.test_classification_gt.clear()\n",
    "        self.log_dict(scores)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        return self(batch), batch.TID\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, self.parameters()), \n",
    "            lr=1e-3\n",
    "        )\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:38.012121Z",
     "iopub.status.busy": "2024-05-28T19:36:38.011781Z",
     "iopub.status.idle": "2024-05-28T19:36:38.428022Z",
     "shell.execute_reply": "2024-05-28T19:36:38.427122Z",
     "shell.execute_reply.started": "2024-05-28T19:36:38.012097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from lightning import seed_everything\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, BaseFinetuning, EarlyStopping, LambdaCallback\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:40.321056Z",
     "iopub.status.busy": "2024-05-28T19:36:40.320401Z",
     "iopub.status.idle": "2024-05-28T19:36:40.328049Z",
     "shell.execute_reply": "2024-05-28T19:36:40.327056Z",
     "shell.execute_reply.started": "2024-05-28T19:36:40.321025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FeatureExtractorFreezeUnfreeze(BaseFinetuning):\n",
    "    def __init__(self, unfreeze_at_epoch=5):\n",
    "        super().__init__()\n",
    "        self._unfreeze_at_epoch = unfreeze_at_epoch\n",
    "\n",
    "    def freeze_before_training(self, pl_module):\n",
    "        self.freeze(pl_module.head.x_embedding1)\n",
    "        self.freeze(pl_module.head.x_embedding2)\n",
    "        self.freeze(pl_module.head.gnns)\n",
    "    \n",
    "    def finetune_function(self, pl_module, current_epoch, optimizer):\n",
    "        if current_epoch == self._unfreeze_at_epoch:\n",
    "            self.unfreeze_and_add_param_group(\n",
    "                modules=[\n",
    "                    # pl_module.head\n",
    "                    pl_module.head.x_embedding1,\n",
    "                    pl_module.head.x_embedding2,\n",
    "                    pl_module.head.gnns\n",
    "                ],\n",
    "                optimizer=optimizer,\n",
    "                train_bn=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:39:13.625467Z",
     "iopub.status.busy": "2024-05-28T19:39:13.624670Z",
     "iopub.status.idle": "2024-05-28T19:39:13.791673Z",
     "shell.execute_reply": "2024-05-28T19:39:13.790777Z",
     "shell.execute_reply.started": "2024-05-28T19:39:13.625427Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    }
   ],
   "source": [
    "trainer_kwargs = {\n",
    "    \"max_epochs\": 10,\n",
    "    \"log_every_n_steps\": 2,\n",
    "    \"limit_train_batches\": 500,\n",
    "    \"limit_val_batches\": 100,\n",
    "    \"limit_test_batches\": 100,\n",
    "    \"check_val_every_n_epoch\": 1, \n",
    "    \"deterministic\": True,\n",
    "    #\"logger\": wandb_logger,\n",
    "}\n",
    "if DRAFT_MODE:\n",
    "    trainer_kwargs['log_every_n_steps'] = 10\n",
    "    trainer_kwargs['limit_train_batches'] = 20\n",
    "    trainer_kwargs['limit_val_batches'] = 10\n",
    "    trainer_kwargs['limit_test_batches'] = 10\n",
    "    trainer_kwargs['max_epochs'] = 2\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    trainer_kwargs[\"accelerator\"] = \"gpu\"\n",
    "    trainer_kwargs['devices'] = [0]\n",
    "\n",
    "# callbacks:\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"saves\", \n",
    "    save_top_k=5, \n",
    "    monitor=\"val_loss\",\n",
    "    filename='{epoch}-{step}-{val_loss:.4f}-{regression_loss/dataloader_idx_0:.4f}-{classif_roc_auc_0:.4f}'\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    'val_loss/dataloader_idx_0',\n",
    "    #'val_loss/dataloader_idx_0', \n",
    "    patience=50\n",
    ")\n",
    "finetuning_callback = FeatureExtractorFreezeUnfreeze(10)\n",
    "def change_loss_on_train_start(trainer, pl_module):\n",
    "    if trainer.current_epoch == 2:\n",
    "        print('current_epoch is 2')\n",
    "    if trainer.current_epoch == 200:\n",
    "        pl_module.ranking_lambda = 0\n",
    "        pl_module.regression_lambda = 0\n",
    "        pl_module.classification_lambda = 1.\n",
    "\n",
    "change_loss_parameters_callback = LambdaCallback(on_train_epoch_start=change_loss_on_train_start)\n",
    "# trainer_kwargs['callbacks'] = [\n",
    "#     #finetuning_callback,\n",
    "#     checkpoint_callback,\n",
    "#     early_stopping,\n",
    "#     change_loss_parameters_callback\n",
    "# ]\n",
    "trainer_kwargs['callbacks'] = [] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:39:15.072124Z",
     "iopub.status.busy": "2024-05-28T19:39:15.071377Z",
     "iopub.status.idle": "2024-05-28T19:39:15.077210Z",
     "shell.execute_reply": "2024-05-28T19:39:15.076064Z",
     "shell.execute_reply.started": "2024-05-28T19:39:15.072094Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:42.739736Z",
     "iopub.status.busy": "2024-05-28T19:36:42.739409Z",
     "iopub.status.idle": "2024-05-28T19:36:42.829403Z",
     "shell.execute_reply": "2024-05-28T19:36:42.828556Z",
     "shell.execute_reply.started": "2024-05-28T19:36:42.739704Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CACHE5\n"
     ]
    }
   ],
   "source": [
    "wandb_project_name = f\"CACHE5\"\n",
    "print(wandb_project_name)\n",
    "#if DRAFT_MODE:\n",
    "#    wandb_logger = WandbLogger(project=wandb_project_name, offline=True)  # , log_model='all')\n",
    "#else:\n",
    "mode = \"DRAFT_MODE\" if DRAFT_MODE else \"FULL_MODE\"\n",
    "wandb_logger = WandbLogger(\n",
    "    project=wandb_project_name,\n",
    "    tags=[\"GIN\", \"MLP\", mode]\n",
    ")  # , log_model='all')\n",
    "\n",
    "# trainer_kwargs['logger'] = wandb_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:44.919230Z",
     "iopub.status.busy": "2024-05-28T19:36:44.918572Z",
     "iopub.status.idle": "2024-05-28T19:36:44.926765Z",
     "shell.execute_reply": "2024-05-28T19:36:44.925834Z",
     "shell.execute_reply.started": "2024-05-28T19:36:44.919196Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/cache5-molclr-baseline-notebook/saves/epoch=64-step=195-val_loss=4.5169-classif_roc_auc_0=0.6545.ckpt\n",
      "../input/cache5-molclr-baseline-notebook/saves/epoch=65-step=198-val_loss=4.6764-classif_roc_auc_0=0.6167.ckpt\n",
      "../input/cache5-molclr-baseline-notebook/saves/epoch=63-step=192-val_loss=4.5763-classif_roc_auc_0=0.5891.ckpt\n",
      "../input/cache5-molclr-baseline-notebook/saves/epoch=66-step=201-val_loss=4.8053-classif_roc_auc_0=0.4975.ckpt\n",
      "../input/cache5-molclr-baseline-notebook/saves/epoch=67-step=204-val_loss=4.8630-classif_roc_auc_0=0.4766.ckpt\n",
      "\n",
      "best: ../input/cache5-molclr-baseline-notebook/saves/epoch=64-step=195-val_loss=4.5169-classif_roc_auc_0=0.6545.ckpt\n"
     ]
    }
   ],
   "source": [
    "SAVEDIR = Path(\"../input/cache5-molclr-baseline-notebook/saves/\")\n",
    "if SAVEDIR.exists():\n",
    "    paths = list(SAVEDIR.glob(\"*ckpt\"))\n",
    "    paths = sorted(paths, key=lambda x: float(x.stem.split(\"=\")[-1]), reverse=True)\n",
    "    for p in paths:\n",
    "        print(p)\n",
    "\n",
    "    best_checkpoint = paths[0]\n",
    "else:\n",
    "    best_checkpoint = \"./epoch=64-step=195-val_loss=4.5169-classif_roc_auc_0=0.6545.ckpt\"\n",
    "print(\"\\nbest:\", best_checkpoint)\n",
    "# \"/kaggle/working/saves/epoch=64-step=195-val_loss=4.5169-classif_roc_auc_0=0.6545.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:39:24.350986Z",
     "iopub.status.busy": "2024-05-28T19:39:24.350279Z",
     "iopub.status.idle": "2024-05-28T19:39:24.594275Z",
     "shell.execute_reply": "2024-05-28T19:39:24.593360Z",
     "shell.execute_reply.started": "2024-05-28T19:39:24.350954Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# model_wrapper = MolCLRWrapper()\n",
    "# best_checkpoint = \"../input/cache5-molclr-baseline-notebook/saves/epoch=5-step=18-val_loss=33.6971-regression_loss/dataloader_idx_0=25.5480-classif_roc_auc_0=0.2299.ckpt\"\n",
    "model_wrapper = MolCLRWrapper.load_from_checkpoint(best_checkpoint, map_location=torch.device('cpu'))\n",
    "trainer = L.Trainer(**trainer_kwargs)\n",
    "# trainer.fit(\n",
    "#     model=model_wrapper, \n",
    "#     train_dataloaders=train_dataloaders,\n",
    "#     val_dataloaders=test_dataloaders\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute metrics on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:39:27.622153Z",
     "iopub.status.busy": "2024-05-28T19:39:27.621561Z",
     "iopub.status.idle": "2024-05-28T19:39:27.627716Z",
     "shell.execute_reply": "2024-05-28T19:39:27.626347Z",
     "shell.execute_reply.started": "2024-05-28T19:39:27.622120Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# trainer.test(\n",
    "#      model=model_wrapper, \n",
    "# #     ckpt_path=\"best\", \n",
    "#     dataloaders=test_dataloaders\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ID (e.g. ID00015)\n",
    "- cls_prb the classification probability\n",
    "- pKi the predicted pKi value\n",
    "- pIC50 the predicted pIC50 value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:53.038250Z",
     "iopub.status.busy": "2024-05-28T19:36:53.037900Z",
     "iopub.status.idle": "2024-05-28T19:36:53.042356Z",
     "shell.execute_reply": "2024-05-28T19:36:53.041249Z",
     "shell.execute_reply.started": "2024-05-28T19:36:53.038221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# test_datasets = [\n",
    "#     CacheDataset(test_df[test_df.acname == acname]) \n",
    "#     for acname in target_names\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:39:31.955222Z",
     "iopub.status.busy": "2024-05-28T19:39:31.954124Z",
     "iopub.status.idle": "2024-05-28T19:39:31.970428Z",
     "shell.execute_reply": "2024-05-28T19:39:31.969331Z",
     "shell.execute_reply.started": "2024-05-28T19:39:31.955179Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TID</th>\n",
       "      <th>SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PV-009095522958</td>\n",
       "      <td>FCC(CF)NC(CF)CF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z5067467525</td>\n",
       "      <td>FC(F)(F)C12CC(NC3CSCSC3)(CO1)C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PV-009234181902</td>\n",
       "      <td>CCN(CC1C2CC3C(C2)C13)C(C)(C)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Z7289498217</td>\n",
       "      <td>Br/C=C\\CN1C2CC3CC1CC(C2)O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PV-008660388768</td>\n",
       "      <td>CC(N[C@H]1[C@@H]2C[C@H]1N[C@@H]2C)C1C(C)(C)C1(C)C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TID                                             SMILES\n",
       "0  PV-009095522958                                    FCC(CF)NC(CF)CF\n",
       "1      Z5067467525                    FC(F)(F)C12CC(NC3CSCSC3)(CO1)C2\n",
       "2  PV-009234181902                      CCN(CC1C2CC3C(C2)C13)C(C)(C)C\n",
       "3      Z7289498217                         Br/C=C\\CN1C2CC3CC1CC(C2)O3\n",
       "4  PV-008660388768  CC(N[C@H]1[C@@H]2C[C@H]1N[C@@H]2C)C1C(C)(C)C1(C)C"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:55.491999Z",
     "iopub.status.busy": "2024-05-28T19:36:55.491646Z",
     "iopub.status.idle": "2024-05-28T19:36:55.496678Z",
     "shell.execute_reply": "2024-05-28T19:36:55.495599Z",
     "shell.execute_reply.started": "2024-05-28T19:36:55.491973Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# selection_ids = data_df.DataSAIL_10f.isin([f\"Fold_{i}\" for i in range(10)])\n",
    "# inference_df = data_df.loc[selection_ids, [\"ID\", \"smiles\"]]\n",
    "\n",
    "# dataset = CacheDataset(\n",
    "#     full_df, \n",
    "#     smiles_column=\"SMILES\", \n",
    "#     inference_mode=True, \n",
    "#     additional_columns=[\"TID\"]\n",
    "# )\n",
    "# inference_loader = DataLoader(\n",
    "#     dataset, \n",
    "#     batch_size=BATCH_SIZE, # num_workers=2\n",
    "# )\n",
    "# len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:39:35.857955Z",
     "iopub.status.busy": "2024-05-28T19:39:35.857354Z",
     "iopub.status.idle": "2024-05-28T19:39:35.871154Z",
     "shell.execute_reply": "2024-05-28T19:39:35.870114Z",
     "shell.execute_reply.started": "2024-05-28T19:39:35.857926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "def predict_for_data_file(\n",
    "        model_wrapper, trainer,\n",
    "        data_file,\n",
    "        save_file, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        num_workers=3, \n",
    "        draft_mode=DRAFT_MODE\n",
    "        ):\n",
    "    if isinstance(data_file, str):\n",
    "        data_file = Path(data_file)\n",
    "    if not data_file.exists():\n",
    "        print(\"Enamine file is not available\")\n",
    "        return None\n",
    "    full_df = pd.read_csv(data_file)\n",
    "    if draft_mode:\n",
    "        full_df = full_df.head(2000)\n",
    "    dataset = CacheDataset(\n",
    "        full_df, \n",
    "        smiles_column=\"SMILES\", \n",
    "        inference_mode=True, \n",
    "        additional_columns=[\"TID\"]\n",
    "    )\n",
    "    print(\"mode:\", draft_mode, len(dataset))\n",
    "    inference_loader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        num_workers=num_workers,\n",
    "        shuffle=False\n",
    "    )\n",
    "    len(dataset)\n",
    "    \n",
    "    columns_order = [\"TID\", \"cls_prb\", \"pKi\", \"pIC50\"]\n",
    "    # predictions = trainer.predict(model_wrapper, inference_loader)\n",
    "    model_wrapper.eval()\n",
    "\n",
    "    # chunk_filename = f'enamine_predictions_chunk_{chunk_number}.csv'\n",
    "    with open(save_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=columns_order)\n",
    "\n",
    "        writer.writeheader()\n",
    "\n",
    "        prediction_batches = trainer.predict(model_wrapper, inference_loader)\n",
    "        for (regression_predictions, classification_predictions), tids in tqdm(prediction_batches):\n",
    "            # regression_predictions, classification_predictions = model_wrapper(batch)\n",
    "            classification_predictions = classification_predictions[:, 1]\n",
    "            data = {k: v.numpy().flatten() for k, v in regression_predictions.items()}\n",
    "            data['cls_prb'] = classification_predictions\n",
    "            data['TID'] = tids\n",
    "            data = pd.DataFrame.from_dict(data).to_dict('records')\n",
    "            writer.writerows(data)\n",
    "\n",
    "    return save_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:36:57.222885Z",
     "iopub.status.busy": "2024-05-28T19:36:57.222531Z",
     "iopub.status.idle": "2024-05-28T19:36:58.984242Z",
     "shell.execute_reply": "2024-05-28T19:36:58.983273Z",
     "shell.execute_reply.started": "2024-05-28T19:36:57.222859Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mlacemaker\u001B[0m (\u001B[33msquirrel-writes-her-phd\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240528_193657-enamine_data5678</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/squirrel-writes-her-phd/CACHE5/runs/enamine_data5678' target=\"_blank\">enamine_data5678</a></strong> to <a href='https://wandb.ai/squirrel-writes-her-phd/CACHE5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/squirrel-writes-her-phd/CACHE5' target=\"_blank\">https://wandb.ai/squirrel-writes-her-phd/CACHE5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/squirrel-writes-her-phd/CACHE5/runs/enamine_data5678' target=\"_blank\">https://wandb.ai/squirrel-writes-her-phd/CACHE5/runs/enamine_data5678</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run = wandb.init(\n",
    "#     project=wandb_project_name,\n",
    "#     id=\"enamine_data5678\",\n",
    "#     resume=\"allow\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:39:38.955458Z",
     "iopub.status.busy": "2024-05-28T19:39:38.954657Z",
     "iopub.status.idle": "2024-05-28T19:39:38.963154Z",
     "shell.execute_reply": "2024-05-28T19:39:38.962033Z",
     "shell.execute_reply.started": "2024-05-28T19:39:38.955424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T19:40:08.172534Z",
     "iopub.status.busy": "2024-05-28T19:40:08.171529Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing chunk 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: False 5000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd1239cac974f2b931f7b6f8aff9ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"start processing chunk 5\")\n",
    "\n",
    "datadir = Path(\"../input/enamine-split-to-chunks\")\n",
    "if datadir.exists():\n",
    "    chunk_number = 5\n",
    "    chunk_size = 5_000_000\n",
    "    data_file = datadir / f\"enamine_chunk_{chunk_number}_{chunk_size}.csv\"\n",
    "    save_file = f\"enamine_predictions_{chunk_number}.csv\"\n",
    "else:\n",
    "    data_file = \"cleaned_enamine.csv\"\n",
    "    save_file = \"cleaned_enamine_predictions.csv\"\n",
    "chunk_filename = predict_for_data_file(\n",
    "    model_wrapper,\n",
    "    trainer,\n",
    "    data_file,\n",
    "    save_file,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    draft_mode=DRAFT_MODE\n",
    ")\n",
    "df = pd.read_csv(chunk_filename)\n",
    "df.to_csv(chunk_filename + \".gz\", compression='gzip', index=None)\n",
    "print(df['TID'].values[:4])\n",
    "\n",
    "# artifact = wandb.Artifact(name=chunk_filename + \".gz\", type=\"data\")\n",
    "# artifact.add_file(chunk_filename + \".gz\")\n",
    "# run.log_artifact(artifact)\n",
    "print(\"end processing chunk 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-28T19:21:58.298706Z",
     "iopub.status.idle": "2024-05-28T19:21:58.299220Z",
     "shell.execute_reply": "2024-05-28T19:21:58.298989Z",
     "shell.execute_reply.started": "2024-05-28T19:21:58.298967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T17:18:55.03617Z",
     "iopub.status.busy": "2024-05-28T17:18:55.035258Z",
     "iopub.status.idle": "2024-05-28T17:18:55.043483Z",
     "shell.execute_reply": "2024-05-28T17:18:55.041058Z",
     "shell.execute_reply.started": "2024-05-28T17:18:55.036134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5004611,
     "sourceId": 8540964,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5101811,
     "sourceId": 8541900,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 177279603,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 180253346,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 180287014,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
